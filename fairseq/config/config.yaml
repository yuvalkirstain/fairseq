# @package _group_

hydra:
  run:
    dir: runs/${now:%Y-%m-%d}/${now:%H-%M-%S}

defaults:
    - _self_
    - checkpoint: default
    - common: default
    - criterion: adaptive_loss
    - dataset: default
    - lr_scheduler: cosine
    - model: transformer_lm/transformer_lm_gpt_wiki2
    - optimization: default
    - optimizer: nag
    - task: language_modeling
    - bpe: null
    - tokenizer: null
    - scoring: null
    - generation: null
    - common_eval: null
    - eval_lm: null

distributed_training:
  ddp_backend: legacy_ddp
  distributed_world_size: 1
